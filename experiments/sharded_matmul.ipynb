{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18877895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import os\n",
    "\n",
    "import jax\n",
    "from jax.experimental import pallas as pl\n",
    "from jax.experimental.pallas import tpu as pltpu\n",
    "import jax.numpy as jnp\n",
    "from jax.sharding import NamedSharding, PartitionSpec as P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02b284a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.config.update('jax_num_cpu_devices', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36a5da36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "def project_root() -> Path:\n",
    "    return Path(subprocess.check_output(\n",
    "        ['git', 'rev-parse', '--show-toplevel']\n",
    "    ).decode().strip())\n",
    "\n",
    "TRACES_DIR = project_root() / \"traces\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79eb75f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "m, k, n = 2048, 2048, 1024\n",
    "\n",
    "k1, k2 = jax.random.split(jax.random.key(0), 2)\n",
    "inputs = jax.random.normal(k1, (m, k), dtype=jnp.bfloat16)\n",
    "weights = jax.random.normal(k2, (k, n), dtype=jnp.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b67d3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/my/845wytg53ln_99j7k_dzpl840000gn/T/ipykernel_67114/3396536806.py:1: DeprecationWarning: The default axis_types will change in JAX v0.9.0 to jax.sharding.AxisType.Explicit. To maintain the old behavior, pass `axis_types=(jax.sharding.AxisType.Auto,) * len(axis_names)`. To opt-into the new behavior, pass `axis_types=(jax.sharding.AxisType.Explicit,) * len(axis_names)\n",
      "  mesh = jax.make_mesh((2, 2), (\"x\", \"y\"))\n"
     ]
    }
   ],
   "source": [
    "mesh = jax.make_mesh((2, 2), (\"x\", \"y\"))\n",
    "inp_sharding = jax.NamedSharding(mesh, P('x', 'y'))\n",
    "w_sharding = jax.NamedSharding(mesh, P('x', None))\n",
    "\n",
    "inputs = jax.device_put(inputs, inp_sharding)\n",
    "weights = jax.device_put(weights, w_sharding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2c93d6",
   "metadata": {},
   "source": [
    "inputs are size 2048, 2048 -> bf16:: 2 bytes * 2048 * 2048 = ~8MB\n",
    "weights are size 2048, 1024 -> bf16:: 2 bytes * 2048 * 1024 = ~4MB\n",
    "\n",
    "inputs sharded along x and y -> $Inp[I_{X}, J_{Y}]$\n",
    "\n",
    "weights sharded along x -> $W[I_{X}, J]$\n",
    "\n",
    "Each device has N elements per array:\n",
    "  - inputs\n",
    "    - (2048 / 2) * (2048 / 2) * 2bytes\n",
    "    - ~2MB\n",
    "  - weights\n",
    "    - (2048 / 2) * 1024 * 2bytes\n",
    "    - ~2MB\n",
    "\n",
    "The contracting dimension is sharded in both inputs and weights, along different axes.\n",
    "Need to handle that with collectives; AG/AR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81e11eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">            </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">            </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">            </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">            </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">   CPU 0    </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">   CPU 1    </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">            </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">            </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">            </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">            </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">            </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">            </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">            </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">            </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">            </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">            </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">   CPU 2    </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">   CPU 3    </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">            </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">            </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">            </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">            </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">            </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m            \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m            \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m   \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121mCPU 0\u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m    \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m   \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214mCPU 1\u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m    \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m            \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m            \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m            \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;173;73;74m            \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m            \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;173;73;74m            \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m            \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;173;73;74m   \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74mCPU 2\u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m    \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m   \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107mCPU 3\u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m    \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;173;73;74m            \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m            \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;173;73;74m            \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m            \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;173;73;74m            \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jax.debug.visualize_array_sharding(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30ea6c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">            </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">            </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">  CPU 0,1   </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">            </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">            </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">            </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">            </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">            </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">  CPU 2,3   </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">            </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">            </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m  \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121mCPU 0,1\u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m   \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m  \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121mCPU 2,3\u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m   \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jax.debug.visualize_array_sharding(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2eae0f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_matmul(x: jax.Array, y: jax.Array) -> jax.Array:\n",
    "    return jnp.matmul(x, y)\n",
    "\n",
    "out = basic_matmul(inputs, weights)\n",
    "compiled = jax.jit(basic_matmul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5a9fdd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">            </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">            </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">  CPU 0,1   </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">            </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">            </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">            </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">            </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">            </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">  CPU 2,3   </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">            </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">            </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m  \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121mCPU 0,1\u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m   \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m  \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121mCPU 2,3\u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m   \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jax.debug.visualize_array_sharding(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f37b47ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = compiled(inputs, weights)\n",
    "result.block_until_ready()\n",
    "\n",
    "with jax.profiler.trace(TRACES_DIR):\n",
    "    result = compiled(inputs, weights)\n",
    "    result.block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa631a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.partial(\n",
    "    jax.shard_map,\n",
    "    mesh=mesh,\n",
    "    in_specs=(P('x', 'y'), P('x', None)),\n",
    "    out_specs=P('x', None),\n",
    "    check_vma=False\n",
    ")\n",
    "def xla_matmul(input_shard: jax.Array, w_shard: jax.Array) -> jax.Array:\n",
    "    # First we want to all_gather the data\n",
    "    with jax.named_scope('all_gather(s)'):\n",
    "        input_full = jax.lax.all_gather(input_shard, 'y', axis=1, tiled=True)\n",
    "        w_full = jax.lax.all_gather(w_shard, 'x', axis=0, tiled=True) # gather w along x\n",
    "    # Then we want to compute on the data\n",
    "    with jax.named_scope('dot'):\n",
    "        local_out = input_full @ w_full\n",
    "    # Then we want to all reduce the data\n",
    "    # with jax.named_scope('all_reduce'):\n",
    "    #     out = jax.lax.psum(local_out, 'y')\n",
    "    return local_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "950f9651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://docs.jax.dev/en/latest/notebooks/shard_map.html\n",
    "from jax.tree_util import tree_map, tree_all\n",
    "\n",
    "def allclose(a, b):\n",
    "  return tree_all(tree_map(functools.partial(jnp.allclose, atol=1e-2, rtol=1e-2), a, b))\n",
    "\n",
    "allclose(xla_matmul(inputs, weights), jnp.dot(inputs, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0e27b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemm2_compiled = jax.jit(xla_matmul)\n",
    "result = gemm2_compiled(inputs, weights)\n",
    "result.block_until_ready()\n",
    "\n",
    "with jax.profiler.trace(TRACES_DIR):\n",
    "    result = gemm2_compiled(inputs, weights)\n",
    "    result.block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8035049d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.partial(\n",
    "    jax.shard_map,\n",
    "    mesh=mesh,\n",
    "    in_specs=(P('x', 'y'), P('x', None)),\n",
    "    out_specs=P('x', None),\n",
    "    check_vma=False\n",
    ")\n",
    "def xla_matmul2(input_shard: jax.Array, weight_shard: jax.Array) -> jax.Array:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb35ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Add the Pallas impl with profiling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sfp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
